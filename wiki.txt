
动态转发（SOCKS5代理）：
命令格式：ssh -D <local port> <SSH Server>
ssh -fnND 0.0.0.0:20058 172.16.50.20  //f后台执行，必须配合n使用，N不打开远程shell，D绑定本地20058端口

ssh -fnND 1080 apps@134.175.160.10 -p 30022

mac:
ssh -qTfnN -D 0.0.0.0:1080 apps@134.175.160.10 -p 30022

#  -q 静默模式 
#  -T 禁用伪终端分配 
#  -f  后台运行 
#  -n  阻止从标准输入读取。后台运行的话，必须使用。 
#  -N 不执行远程命令 
#  -D [bind_address : port] 本地动态应用级端口转发。没有指定address将监听在127.0.0.1上。



-g Allow remote hosts to connect to forwarded ports.
在-L/-R/-D参数中，允许远程主机连接到建立的转发的端口，如果不加这个参数，只允许本地主机建立连接。

修改配置文件 ~#vi /etc/ssh/sshd_config
在文件最后加入 gatewayports yes 


本地端口转发：
有时，绑定本地端口还不够，还必须指定数据传送的目标主机，从而形成点对点的"端口转发"。为了区别后文的"远程端口转发"，我们把这种情况称为"本地端口转发"（Local forwarding）。
假定host1是本地主机，host2是远程主机。由于种种原因，这两台主机之间无法连通。但是，另外还有一台host3，可以同时连通前面两台主机。因此，很自然的想法就是，通过host3，将host1连上host2。
我们在host1执行下面的命令：
    　　$ ssh -L 2121:host2:21 host3
命令中的L参数一共接受三个值，分别是"本地端口:目标主机:目标主机端口"，它们之间用冒号分隔。这条命令的意思，就是指定SSH绑定本地端口 2121，然后指定host3将所有的数据，转发到目标主机host2的21端口（假定host2运行FTP，默认端口为21）。
这样一来，我们只要连接host1的2121端口，就等于连上了host2的21端口。
    　　$ ftp localhost:2121
"本地端口转发"使得host1和host3之间仿佛形成一个数据传输的秘密隧道，因此又被称为"SSH隧道"。


不用代理之前：
git clone git@git.nome.com:golang/auroramall.git

使用隧道代理：
ssh -fnNL 2222:git.nome.com:22 apps@134.175.160.10 -p 30022
git clone ssh://git@127.0.0.1:2222/golang/auroramall.git

远程端口转发：
既然"本地端口转发"是指绑定本地端口的转发，那么"远程端口转发"（remote forwarding）当然是指绑定远程端口的转发。
还是接着看上面那个例子，host1与host2之间无法连通，必须借助host3转发。但是，特殊情况出现了，host3是一台内网机器，它可以连接外网的host1，但是反过来外网的host1连不上内网的host3。这时，"本地端口转发"就不能用了，怎么办？
解决办法是，既然host3可以连host1，那么就从host3上建立与host1的SSH连接，然后在host1上使用这条连接就可以了。
我们在host3执行下面的命令：
    　　$ ssh -R 2121:host2:21 host1
R参数也是接受三个值，分别是"远程主机host1端口:目标主机:目标主机端口"。这条命令的意思，就是让host1监听它自己的2121端口，然后将所有 数据经由host3，转发到host2的21端口。由于对于host3来说，host1是远程主机，所以这种情况就被称为"远程端口绑定"。
绑定之后，我们在host1就可以连接host2了：
    　　$ ftp localhost:2121
这里必须指出，"远程端口转发"的前提条件是，host1和host3两台主机都有sshd服务器和ssh客户端。

host1(172.16.2.164)，host3(172.16.50.20)，host2(192.168.1.130)
host1和host3互通，host1无法访问host2，host3可以访问host2
现在host1需要访问host2的80端口，那么可以在host1上运行ssh -fnNL 5900:192.168.1.130:80 172.16.50.20
或者在host3上运行ssh -fnNR 5900:192.168.1.130:80 172.16.2.164即可

killp:
#!/bin/bash
if [ "$#" -lt "1" ];then
	echo "Usage: killp keyword."
	exit
fi
for i in `ps -ef |grep "$i"|grep -v "grep"|awk '{print $2}'`;do kill -9 $i;done;


autossh:
for ip in `cat ip.txt`
do
expect <<end
set timeout 2
spawn ssh-copy-id -i clouder@$ip
expect {
"yes/no" {send "yes\r";exp_continue}
}
expect "password:"
set timeout 2
send "engine\r"
expect eof
end
done


限速：
yum install -y wondershaper

tc qdisc add dev eth0 root tbf rate 10Mbit latency 50ms burst 10000 mpu 64
tc qdisc del dev eth0 root
tc -s qdisc ls dev eth0


export GTK_IM_MODULE=ibus
export XMODIFIERS=


export LANG="zh_CN.UTF-8"
export LC_CTYPE="zh_CN.UTF-8"
export GTK_IM_MODULE="scim"
export XMODIFIERS="@im=SCIM"
export QT_IM_MODULE="scim"
export XIM=SCIM
export XIM_PROGRAM=SCIM


export GTK_IM_MODULE=ibus
export XMODIFIERS=@im=ibus
export QT_IM_MODULE=ibus


ORACLE
1.修改/etc/hosts,运行netmgr配置监听，再查看tnsnames.ora及listener.ora文件
2.启动数据库：
sqlplus sys/engine as sysdba
SQL>startup 
SQL>show parameter local_listener  
3.启动监听：
lsnrctl start
lsnrctl status
4.如果要开机自动启动，修改/etc/oratab;然后在rc.local里面添加su oracle -lc "dbstart $ORACLE_HOME"、su oracle -lc "lsnrctl start"


mysql绿色安装：
下载tar.gz包，export TMPDIR=/tmp;export MYSQL_UNIX_PORT=/tmp/mysql.sock
运行script中的安装脚本：./mysql_install_db --basedir=/home/clouder/soft/mysql/mysql-5.5.10-linux2.6-x86_64 --datadir=/home/clouder/soft/mysql/mysql-5.5.10-linux2.6-x86_64/data --skip-name-resolve --user=clouder

在mysql bin目录中编写startmysql脚本：
#!/bin/bash
SCRIPT_PATH=`dirname "$0"`
SCRIPT_PATH=`cd ${SCRIPT_PATH};pwd`
$SCRIPT_PATH/mysqld --basedir=$SCRIPT_PATH/../ &

shutdownmysql脚本：
#!/bin/bash
SCRIPT_PATH=`dirname "$0"`
SCRIPT_PATH=`cd ${SCRIPT_PATH};pwd`
$SCRIPT_PATH/mysqladmin -uroot -p shutdown




http://li.nux.ro/download/nux/dextop


正确的使用dd进行磁盘读写速度测试：
if=xxx  从xxx读取，如if=/dev/zero,该设备无穷尽地提供0,（不产生读磁盘IO）
of=xxx  向xxx写出，可以写文件，可以写裸设备。如of=/dev/null，"黑洞"，所有写入它的内容都会永远丢失. （不产生写磁盘IO）
conv=sync   操作系统“写缓存”起作用,不加conv参数时默认使用该选项
conv=fsync  表示把文件的“数据”和“metadata”都写入磁盘（metadata包括size、访问时间st_atime & st_mtime等等），因为文件的数据和metadata通常存在硬盘的不同地方，因此fsync至少需要两次IO写操作，fsync 与fdatasync相差不大。
conv=fdatasync  表示只把文件的“数据”写入磁盘，fsync与fdatasync相差不大。

对磁盘进行连续写入，不使用内存缓冲区，每次写入8k的数据，总共写入20万次
dd if=/dev/zero of=test.bin bs=8k count=200000 conv=fdatasync


利用netcat命令进行远程备份：
在目的主机上执行此命令来接收数据并写入到文件chrome.rpm
nc -l -p 20058 | dd of=chrome.rpm bs=4M

在源主机上执行此命令发送文件chrome.rpm
dd if=chrome.rpm bs=4M| nc < targethost-IP > 20058


同步时间：
ssh root@ip date -s @`date +%s.%N`  //修改ip的时间


centos 6.6 xdmcp远程桌面：
1.首先安装 xdm软件：yum install xdm
vi /etc/X11/xdm/Xaccess:
* allow

vi /etc/gdm/custom.conf:
[security]
AllowRemoteRoot=true

[xdmcp]
Enable=true
Port=177


2.设置某用户的密码过期时间，使用usermod -e
如果要统一设置用户的密码过期时间，那么就要修改/etc/login.defs里面的PASS_MAX_DAYS，比如修改所有用户的密码过期时间是30天：
PASS_MAX_DAYS 30,值为99999，表示密码永不过期。
linux下设置与修改用户失效时间及密码失效时间，用法：chage [选项] 用户名,chage -E 2010-09-30 zjd
chage -l zjd  列出账户密码策略


select ﻿date_add('2014-04-17 2:00:00', interval '1:10:10' hour_second); 
select date_add(日期, interval 1 day); 




列出某个IP地址所提供的共享文件夹
smbclient -L 198.168.0.1 -U username%password
像FTP客户端一样使用smbclient
smbclient //192.168.0.1/tmp  -U username%password

mount -t cifs -o  username=administrator,password=123456,iocharset=utf8,sec=ntlm //192.168.0.1/tmp  /mnt/tmp
smbmount //192.168.0.1/tmp /mnt/tmp -o username=administrator



出现以下信息：
    Enter passphrase for key '/home/qingxu/.ssh/id_dsa':  
执行：
eval `ssh-agent`
ssh-add


watch

time echo "scale=5000;4*a(1)" | bc -l -q




sar 2 3 每隔2s，共采集3次
1. 若 %iowait 的值过高，表示硬盘存在I/O瓶颈
2. 若 %idle 的值高但系统响应慢时，有可能是 CPU 等待分配内存，此时应加大内存容量
3. 若 %idle 的值持续低于1，则系统的 CPU 处理能力相对较低，表明系统中最需要解决的资源是 CPU 

sar -b 2 3

要判断系统瓶颈问题，有时需几个 sar 命令选项结合起来

怀疑CPU存在瓶颈，可用 sar -u 和 sar -q 等来查看

怀疑内存存在瓶颈，可用 sar -B、sar -r 和 sar -W 等来查看

怀疑I/O存在瓶颈，可用 sar -b、sar -u 和 sar -d 等来查看



# cat nvdisk-test
[global]
bs=512
ioengine=libaio
userspace_reap
rw=randrw
rwmixwrite=20
time_based
runtime=180
direct=1
group_reporting
randrepeat=0
norandommap
ramp_time=6
iodepth=16
iodepth_batch=8
iodepth_low=8
iodepth_batch_complete=8
exitall
[test]
filename=/dev/nvdisk0
numjobs=1

1. libaio工作的时候需要文件direct方式打开。
2. 块大小必须是扇区的倍数。
3. userspace_reap提高异步IO收割的速度。
4. ramp_time的作用是减少日志对高速IO的影响。
5. 只要开了direct,fsync就不会发生。
6. stonewall#等待上一个任务完成再开始


vi无权限写文件
:w !sudo tee %


硬盘性能指标
顺序读写 （吞吐量，常用单位为MB/s）：文件在硬盘上存储位置是连续的。适用场景：大文件拷贝（比如视频音乐）。速度即使很高，对数据库性能也没有参考价值。
4K随机读写 （IOPS，常用单位为次）：在硬盘上随机位置读写数据，每次4KB。适用场景：操作系统运行、软件运行、数据库。


以下是使用通用I/O测试工具“fio”，并在指定数据块大小“4K、512K”、队列深度为“128”的条件下，对“SAS”以及“SSD”这两种机型磁盘进行的I/O基准性能测试所得出的测试数据。
bw：磁盘的吞吐量，这个是顺序读写考察的重点
iops：磁盘的每秒读写次数，这个是随机读写考察的重点


fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randrw -rwmixread=70 -size=2G -filename=/dev/sdb -name="4K randrw test" -iodepth=1 -runtime=60
unitestack:
read : io=26500KB, bw=452244B/s, iops=110, runt= 60003msec
write: io=11436KB, bw=195164B/s, iops=47, runt= 60003msec



fio -ioengine=libaio -bs=512k -direct=1 -thread -rw=read -size=100G -filename=/dev/sdb -name="512k read test" -iodepth=1 -runtime=60
unitestack:
read : io=2048.0MB, bw=96368KB/s, iops=188, runt= 21762msec

fio -ioengine=libaio -bs=512k -direct=1 -thread -rw=write -size=100G -filename=/dev/sdb -name="512k write test" -iodepth=1 -runtime=60
write: io=1700.0MB, bw=29011KB/s, iops=56, runt= 60005msec


#CentOSè‹±æ–‡çŽ¯å¢ƒä¸‹ä½¿ç”¨ä¸­æ–‡è¾“å…¥æ³•
cp /usr/share/locale/zh_CN/LC_MESSAGES/ibus* /usr/share/locale/en_US/LC_MESSAGES
vi /etc/X11/xinit/xinitrc.d/50-xinput.sh
_im_language_list=
add "en"

#è§£å†³Linuxä¸‹Sparkçš„ä¹±ç é—®é¢˜
mkdir /home/clouder/programs/spark/jre/lib/fonts
mkdir /home/clouder/programs/spark/jre/lib/fonts/fallback
cd /home/clouder/programs/spark/jre/lib/fonts/fallback
ln -s /usr/share/fonts/wqy-zenhei/wqy-zenhei.ttc
mkfontdir
mkfontscale


blkid查看uuid



git乱码：
git config --global core.quotepath false
git config --global gui.encoding utf-8
git config --global i18n.commitencoding utf-8
git config --global i18n.logoutputencoding gbk
export LESSCHARSET=utf-8


mkdir testgit
cd testgit
git init
git add .
git commit -m "init"
git remote add origin ssh://你的IP/~/testgit/.git
git push origin master
git remote show origin //显示远程信息



for i in `ls  fio_randrd*`;do mv -f $i `echo $i |sed 's/randrd/randread/'`;done



xenserver挂载ISO：
1、通过ssh或者是xenCenter登录到xenserver用 " vgdisplay " 查看卷组信息，并把VG Name记录下来
  lvdisplay VG_XenStorage-205eecff-2466-84fe-56d5-81472e44f3c2 #查看该区

2、在VG上创建用于存放ISO的 LV（逻辑卷），并分配大小和命名，我觉得给他20G就够了，名字就叫local_iso吧
  #lvcreate -L 20G -n local_iso  VG_XenStorage-f648889e-43d3-84cc-724e-9ee3ddf967b0

3、格式化刚创建的LV

    # mkfs.ext3  /dev/VG_XenStorage-f648889e-43d3-84cc-724e-9ee3ddf967b0/local_iso

4、创建本地挂载目录

   #mkdir /local_iso

   vgchange -a y #激活所有卷组

5、通过编辑/etc/fstab 来设置自动挂载刚刚创建的逻辑卷

   #vi /etc/fstab

   在 /etc/fstab里添加这一行/dev/VG_XenStorage-f648889e-43d3-84cc-724e-9ee3ddf967b0/local_iso    /local_iso    ext3   defaults 0 0

6、用mount命令挂载逻辑卷

   #mount /local_iso

7、用wget下载工具把 Internet 上的ISO文件下载到 /localhost_iso目录

wget -c http://mirror.stanford.edu/yum/pub/centos/5.8/isos/x86_64/CentOS-5.8-x86_64-bin-DVD-1of2.iso

8、使用 xe 命令创建SR

   #xe sr-create name-label=local_iso type=iso device-config:location=/local_iso device-config:legacy_mode=true content-type=iso

9、xenCenter 连接到xenserver后会发现多了一个iso_image的本地存储，如果iso_image里没有刚下载的ISO文件的话那么使用以下命令更新一下

    #xe-mount-iso-sr /local_iso
    #xe-toolstack-restart 
OK，大功告成，这样子安装VM的时候就可以用local_iso里的ISO文件了



pkgs.org
www.rpmfind.net




raid：

查看raid信息：
cat /proc/mdstat
mdadm -D /dev/md127

创建阵列：
mdadm -C /dev/md127 -c=512 -l 0 -n 4 /dev/sd{a,b,c,d}
mdadm --create /dev/md127 --chunk=512 --level=0 --raid-devices=4 /dev/sd{a,b,c,d}
mdadm不采用/etc/mdadm.conf作为主要配置文件，它可以完全不依赖该文件而不会影响阵列的正常工作。该配置文件的主要作用是方便跟踪软RAID的配置。对该配置文件进行配置是有好处的，但不是必须的。推荐对该文件进行配置。
格式：
DEVICE 参与阵列的设备
ARRAY 阵列的描述

通常可以这样来建立：
echo DEVICE /dev/sd{b,c,d}1 >> /etc/mdadm.conf
mdadm -D --scan >> /etc/mdadm.conf

结果如下：
# cat /etc/mdadm.conf
DEVICE /dev/sdb1 /dev/sdc1 /dev/sdd1
ARRAY /dev/md0 level=raid0 num-devices=3 UUID=8ba81579:e20fb0e8:e040da0e:f0b3fec8

##查看阵列详细信息
mdadm -D /dev/md127 或mdadm --detail /dev/md127

停止阵列：
mdadm -S /dev/md127  #注意：停止后，原组成阵列的磁盘将处于空闲状态，一旦误操作这些磁盘，将不能再重启激活原阵列。

软RAID是基于系统的，当原系统损坏了，需要重新装配。将上述已经停止的阵列重新激活：
mdadm -A /dev/md127 /dev/sd{a,b,c,d}

可以使用--fail指定坏磁盘，并--remove走：
mdadm /dev/md0 --fail /dev/sdc1 --remove /dev/sdc1
※需要注意的是，对于某些阵列模式，如RAID0等，是不能用--fail和--remove的。

增加一个新的磁盘到阵列:
mdadm /dev/md0 --add /dev/sdc1
※需要注意的是，对于某些阵列模式，如RAID0等，是不能用--add的。




iscsi:
pvcreate /dev/md127
vgcreate iscsi /dev/md127
vgdisplay iscsi
lvcreate iscsi --name target1 -L 2000G
lvdisplay

mdadm -S /dev/md127
mdadm --misc --zero-superblock /dev/sda
mdadm --misc --zero-superblock /dev/sdb
mdadm --misc --zero-superblock /dev/sdc
mdadm --misc --zero-superblock /dev/sdd

mdadm -D /dev/md127

vgremove iscsi --force


我们有这样的需求：Linux系统下一个文件不允许别人修改、删除或者只允许添加，我们就可以使用chattr命令。chattr +i test.txt





CentOS 7网卡名重命名：
vi /etc/sysconfig/grub
增加“net.ifnames=0 biosdevname=0”，编辑后的文件内容：
GRUB_CMDLINE_LINUX=”rd.lvm.lv=vg0/swap vconsole.keymap=us crashkernel=auto  vconsole.font=latarcyrheb-sun16 net.ifnames=0 biosdevname=0 rd.lvm.lv=vg0/usr rhgb quiet”
执行：grub2-mkconfig -o /boot/grub2/grub.cfg
重启后重命名并修改/etc/sysconfig/network-scripts/ifcfg-*




[root@localhost ~]# rpcinfo -p 192.168.145.100
[root@localhost ~]# showmount -e 192.168.145.100 查看145.100上的共享文件
fuser -kv /mnt/public




svn export -r 11893 svn://172.16.2.139/qa/test.txt #导出版本11893 test.txt
svn log test.txt -l 5  #查看最近5条记录



ethtool eth1
dhclient eth1


telnet测试邮件服务器
telnet ip 25
helo test
auth login
此时提示：334 输入用户名：（用echo -n "username" |base64）
然后提示输入密码：（用echo -n "password" |base64）
mail from:
rcpt to:
data
subject:test
邮件正文(以.然后回车换行结束并发送)




iscsi Target (TGT) 
配置target.conf (TGT) 
 vim /etc/tgt/targets.conf 
//添加如下 
<target iqn.2012-04.com.test:server.target1> 
    backing-store /dev/VolGroup/iscsi
    lun 10 
</target> 
 
//此配置文档语法如下： 
<target iqn.相关装置的target名称> 
    backing-store /你的/虚拟装置/完整名称-1  <==LUN 1 
    backing-store /你的/虚拟装置/完整名称-2  <==LUN 2 
    lun N                                 <==LUN 10 自定义lun
</target> 
//iqn 名称规范 
iqn.yyyy-mm.<reversed domain name>:identifier 
iqn.年年-月.单位网域名的反转写法:这个分享的target名称 
 
启动并检查tgt  
[root@localhost yum.repos.d]# /etc/init.d/tgtd start 
//tgtd 进程使用 tcp 3260 端口 
# lsof -i :3260 


linux initiator 设置
检查系统是否安装 iscsi-target-utils 
//iscsi-initiator-utils：挂载target 的磁盘到Linux 本机上 
$ rpm -qa | grep scsi 
iscsi-initiator-utils-6.2.0.871-0.10.el5 
 
iscsi initiator 配置文档与管理程序 
/etc/iscsi/iscsid.conf  主要的配置文档，用于连接到 iSCSI target 
/sbin/iscsid            启动 iSCSI initiator 的服务进程 
/sbin/iscsiadm          用于管理 iSCSI initiator  
/etc/init.d/iscsid      模拟成 iSCSI initiater 的服务 
/etc/init.d/iscsi       在本机成为 iSCSI initiator 后，会调用此脚本，用于登入 iSCSI target 
/etc/iscsi/initiatorname.iscsi  initiator 名称
 
启动 iscsi-initiator  
$ systemctl start iscsi 
systemctl enable iscsi




査看可用的target 
iscsiadm -m node

载入target
iscsiadm -m node -T iqn.2015-07.wiscom:wiscom20 -p 10.10.11.7:3260 -l

卸载target
$ iscsiadm -m node -T iqn.2012-04.com.test:server.target1 --logout 

删除target  
//刪除 target 连接信息，再次 ll /var/lib/iscsi/nodes/ 为0 
192.168.57.71 [~]$ iscsiadm -m node -o delete -T iqn.2012-04.com.test:server.target1
tgt-admin -s 或者tgtadm --lld iscsi --mode target --op show 都可以查看qin号、设备连接信息和scsi_id号
iscsiadm --mode discoverydb --type sendtargets --portal 192.168.1.10

iscsiadm -m discovery -t st -p 10.10.11.7:3260


-m discovery　　//侦测target
-t sendtargets　　//通过iscsi协议
-p IP:port　　//指定target的IP和port，不写port的话，默认为3260


查看目前连接状态：iscsiadm -m session
刪除所有 node 信息 (需重新 discovery) ：iscsiadm -m node --op delete 

iscsiadm -m session -i 查看挂载盘的信息
iscsiadm -m node -U all 卸载





批量替换文件夹中字符串：
1、sed -i 's/172.16.15.18/192.168.70.91/g' *.sh
2、find . -name "*.sh" -exec sed -i 's/172.16.15.18/192.168.70.91/g' {} \;
3、find . -name "*.sh" |xargs sed -i 's/172.16.15.18/192.168.70.91/g'
4、grep -irl '172.16.15.18' |xargs sed -i 's/172.16.15.18/192.168.70.91/g'


xargs:
-n:每行最多n个数据
-I:使用-I指定一个替换字符串{}，这个字符串在xargs扩展时会被替换掉，当-I与xargs结合使用，每一个参数命令都会被执行一次
echo "1.log 2.log 3.log" >arg.txt
cat arg.txt | xargs -I {} touch  {}

用rm 删除太多的文件时候，可能得到一个错误信息：/bin/rm Argument list too long. 用xargs去避免这个问题：
find . -type f -name "*.log" -print0 | xargs -0 rm -f

统计一个源代码目录中所有php文件的行数： 
find . -type f -name "*.php" -print0 | xargs -0 wc -l

查找所有的jpg 文件，并且压缩它们： 
find . -type f -name "*.jpg" -print | xargs tar -czvf images.tar.gz


-exec和xargs的区别：

在使用find命令的-exec选项处理匹配到的文件时，find命令将所有匹配到的文件一起传递给exec执行。但有些系统对能够传递给exec的命令长度有限制，这样在find 命令运行几分钟之后，就会出现溢出错误。错误信息通常是“参数列太长”或“参数列溢出”。且在有些系统中，使用-exec选项会为处理每一个匹配到的文件而发起一个相应的进程，并非将匹配到的文件全部作为参数一次执行；这样在有些情况下就会出现进程过多， 系统性能下降的问题，因而效率不高

而xargs命令每次只获取一部分参数而不是全部，不像-exec选项那样一次获取所有参数。这样它可以先处理 最先获取的一部分文件，然后是下一批，并如此继续下去。且使用xargs命令则只有一个进程。另外，在使用xargs命令时，究竟是一次获取所有的参数，还是分批取得参数，以及每一次获取参数的数目都会根据该命令的选项及系统内核中相应的可调参数来确定。

默认情况下, find每输出一个文件名, 后面都会接着输出一个换行符 ('\n'), 因此我们看到的find的输出都是一行一行的。xargs 默认是以空白字符 (空格, TAB, 换行符) 来分割记录的, 因此文件名 file 1.log 被解释成了两个记录 file 和 1.log, 不幸的是 rm 找不到这两个文件.为了解决此类问题, 聪明的人想出了一个办法, 让 find 在打印出一个文件名之后接着输出一个 NULL 字符 ('\0') 而不是换行符, 然后再告诉 xargs 也用 NULL 字符来作为记录的分隔符. 这就是 find 的 -print0 和 xargs 的 -0 的来历.


-exec
    1.所有参数一次性接收，但匹配到一个参数就执行一次，效率低
    2.文件名有空格等特殊字符也能处理
-xargs 
    1.一次将参数传给命令，可以使用-n控制参数个数
    2.处理特殊文件名需要采用如下方式：find . -name "*.txt" -print0 |xargs -0 rm {} 
技巧： find -print0  与 xargs -0 的结合避免文件名有特殊字符如空格，引号等无法处理：
    3.有些命令不支持多个参数，需要用-n 1


find . -name "*.txt"  -exec echo {} \;
find . -name "*.txt"  -exec echo {} +
find . -name "*.txt" |xargs echo
find . -name "*.txt" |xargs -n 1 echo


优化系统：
编辑/etc/security/limits.conf  增加或修改以下配置：
vim /etc/security/limits.conf
 # 添加或修改如下的行
* soft nproc 131072
* hard nproc 131072
* soft nofile 655350
* hard nofile 655350


编辑/etc/sysctl.conf  增加或修改以下配置：
vi /etc/sysctl.conf
 # 添加或修改如下的行
fs.file-max = 6815744
net.ipv4.tcp_max_tw_buckets = 20000


检查磁盘状态：
smartctl -i /dev/sda
smartd


keepalived:
/sbin/ifconfig lo:0 192.168.1.240 broadcast 192.168.1.240 netmask 0xffffffff up
/sbin/route add -host 192.168.1.240 dev lo:0


ceph -s or ceph status
ceph osd stat  //检查ceph osd的状态
ceph mon stat  //检查ceph mon的状态
ceph mds stat  //检查MDS状态
ceph -w  //观看集群正在发生的事件
ceph df  //查看ceph存储空间


for i in {1..10000};do echo ptest$i >>username.txt;done
sed -i 's/$/\r/' username.txt  //转换成dos格式

netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'

route-eth0:
ADDRESS0=192.168.1.0
NETMASK0=255.255.255.0
GATEWAY0=192.168.1.79
ADDRESS1=172.16.0.0
NETMASK1=255.255.0.0
GATEWAY1=192.168.0.200




loadrunner:
double trans_time; 
trans_time=lr_get_transaction_duration( "login" );  //lr_get_transaction_duration这个函数可以得到事务执行所消耗的时间

    if (trans_time) //如果该事务消耗了时间输出该时间
        lr_output_message("tr_login事务耗时 %f 秒", trans_time);
    else //如果该事务没有消耗时间，那么输出时间不确定
        lr_output_message("The duration cannot be determined.");


    if (atoi(lr_eval_string("{login_Count}")) > 0)

       { 
       //如果在登陆后的页面中找到“ERROR”这个字符串，我们认为登陆失败
      lr_error_message("Login failed");
        }
    else
       {
        //否则登陆成功
     lr_output_message("Login successful."); 
    return(0); 
       }


    if (status == 0) //如果成功
     lr_end_transaction("login", LR_PASS);//如果提交成功，设置事务状态为PASS
    else 
     lr_end_transaction("login", LR_FAIL);//如果提交失败，设置事务状态为FAIL



mysql：
取得当天：
SELECT curdate();
mysql> SELECT curdate();

取得前一天：
mysql> select date_sub(curdate(),interval 1 day);



linux文件分割与合并：
split -d -b 10m jmeter.tar.bz2 jmeter
cat jmeter* > jmeter.tar.bz2



并发参数优化：
vi /etc/sysctl.conf
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_fin_timeout = 15
net.ipv4.tcp_keepalive_probes = 5  #TCP发送keepalive探测以确定该连接已经断开的次数
net.ipv4.tcp_keepalive_intvl = 15  #探测消息发送的频率
net.ipv4.tcp_max_syn_backlog = 8192  #表示SYN队列的长度
net.ipv4.tcp_max_tw_buckets = 819200

如果变更后运行命令netstat -s|grep timestamp
发现packets rejects in established connections because of timestamp
数值增加的很快，你可能得回滚这个变更了：说明使用snat访问你网站的人很多
因为：虽然服务器端没有使用nat，但是客户端使用snat的情况很多，如果后发现packets rejects in established connections because of timestamp增长很快，建议将这个方案回滚。那时，可使用修改net.ipv4.tcp_max_tw_buckets（centos默认似乎是 262144）可调整至100000。其实也说明，timeout数量不大的时候，其实可以不用调整tcp_tw_recycle参数（风险很大）。




如果在压力测试的时候,并发数增大,但无法完成测试,可以尝试调整下参数: 
vi /etc/sysctl.conf 
在kernel2.6之前的添加项： 
net.ipv4.netfilter.ip_conntrack_max = 655360 
net.ipv4.netfilter.ip_conntrack_tcp_timeout_established = 180 
 
kernel2.6之后的添加项： 
net.nf_conntrack_max = 655360  # net.nf_conntrack_max = 655360 也可以 
net.netfilter.nf_conntrack_tcp_timeout_established = 1200 



firewall-cmd --zone=public --add-port=80/tcp --permanent



xen server:
xe vm-list
xe pool-param-set uuid=... other-config:auto_poweron=true
xe vm-param-set uuid=... other-config:auto_poweron=true


jmeter关联，利用正则提取表达式：
　　（1）引用名称：下一个请求要引用的参数名称，如填写title，则可用${title}引用它。

　　（2）正则表达式（.+?)：

　　　　()：括起来的部分就是要提取的。
　　　　.：匹配任何字符串。
　　　　+：一次或多次。
　　　　?：不要太贪婪，在找到第一个匹配项后停止。

　　（3）模板：用$$引用起来，如果在正则表达式中有多个正则表达式，则可以是$2$$3$等等，表示解析到的第几个值给title。如：$1$表示解析到的第1个值

　　（4）匹配数字：0代表随机取值，1代表全部取值，通常情况下填0

　　（5）缺省值：如果参数没有取得到值，那默认给一个值让它取。



egrep '(vmx|svm)' /proc/cpuinfo

cloudstack:
/etc/cloudstack/management/db.properties
cluster.node.IP:管理节点的IP地址
db.cloud.username:数据库用户名
db.cloud.password:加密的数据库密码
db.cloud.host:数据库所在节点IP
db.cloud.port:数据库端口
日志：/var/log/cloudstack/management/management-server.log

Expunge.delay ：设置删除的延时
Expunge.interval ：设置删除的时间间隔
Cpu.overprovisioning.factor ：设置CPU超分 



添加路由：
ip route add 10.15.150.0/24 via 192.168.150.253 dev enp0s3
删除路由：
ip route del 10.15.150.0/24

1、添加永久静态路由

ip route 指令对路由的修改不能保存，重启就没了。把 ip route 指令写到 /etc/rc.local 也是徒劳的。

RHEL7官网文档没有提到 /etc/sysconfig/static-routes，经测试此文件已经无效；

/etc/sysconfig/network 配置文件仅仅可以提供全局默认网关，语法同 Centos6 一样： GATEWAY=<ip address> ；

永久静态路由需要写到 /etc/sysconfig/network-scripts/route-interface 文件中，比如添加两条静态路由：

[root@centos7 ~]# vi /etc/sysconfig/network-scripts/route-eth0
default via 192.168.1.79 dev eth0
172.16.0.0/16 via 192.168.0.200 dev eth0


在/etc/sysconfig/static-routes中添加路由

如果你有多个网卡，并且有多个网关，就要通过这种方式设置路由，重启网卡设置就会生效。添加的内容和route命令相似：

any host 192.168.1.11 gw 192.168.1.1
any net 192.168.2.0/24 gw 192.168.1.8
any net 192.168.3.0/24 gw 192.168.67.2


一：使用 route 命令添加
使用route 命令添加的路由，机器重启或者网卡重启后路由就失效了，方法：
//添加到主机的路由
# route add –host 192.168.1.11 dev eth0
# route add –host 192.168.1.12 gw 192.168.1.1
//添加到网络的路由
# route add –net 192.168.1.11  netmask 255.255.255.0 eth0
# route add –net 192.168.1.11  netmask 255.255.255.0 gw 192.168.1.1
# route add –net 192.168.1.0/24 eth1
//添加默认网关
# route add default gw 192.168.2.1
//删除路由
# route del –host 192.168.1.11 dev eth0



Iozone可以测试顺序和随机的文件io性能。在命令行上使用-o参数，可以使测试工作在SYNC模式上。命令输出结果中的rewrite指标可近似看做磁盘的IOPS值。
./iozone -i 0 -i 1 -r 4K -s 1G -o -I -f /test
参数说明
-i 后面加数字，表示测试内容，范围从0到12，常用的有3项，0=写或者重写，1=读或者重读 ，2=随机读写，0选型是必须的。
-r 测试块大小
-s 测试文件大小
-o 采用O_sync方式
-f 测试文件路径
-I 关闭文件系统缓存


fio -ioengine=libaio -bs=512k -direct=1 -thread -rw=write -size=500G  -directory=/mnt -filename=fiotest -iodepth=1 -name=qatest -runtime=100
fio -ioengine=libaio -bs=4k -direct=1 -thread -rw=randrw -rwmixread=70 -filename=/dev/sdb -iodepth=32  -name=qatest -ramp_time=300 -runtime=100 -group_reporting



Vim查找替换及正则表达式的使用：
简单替换表达式

:[range]s/from/to/[flags]

    range:搜索范围，如果没有指定范围，则作用于但前行。
        :1,10s/from/to/ 表示在第1到第10行（包含第1，第10行）之间搜索替换；
        :10s/from/to/ 表示只在第10行搜索替换；
        :%s/from/to/ 表示在所有行中搜索替换；
        1,$s/from/to/ 同上。

    flags 有如下四个选项：
        c confirm，每次替换前询问；
        e error， 不显示错误；
        g globle，不询问，整行替换。如果不加g选项，则只替换每行的第一个匹配到的字符串；
        i ignore，忽略大小写。

    这些选项可以合并使用，如cgi表示不区分大小写，整行替换，替换前询问。

正则表达式

    元字符

        元字符
        元字符	说明
        . 	匹配任意字符
        [abc] 	匹配方括号中的任意一个字符，可用-表示字符范围。如[a-z0-9]匹配小写字母和数字
        [^abc] 	匹配除方括号中字符之外的任意字符
        \d 	匹配阿拉伯数字，等同于[0-9]
        \D 	匹配阿拉伯数字之外的任意字符，等同于[^0-9]
        \x 	匹配十六进制数字，等同于[0-9A-Fa-f]
        \X 	匹配十六进制数字之外的任意字符，等同于[^0-9A-Fa-f]
        \l 	匹配[a-z]
        \L 	匹配[^a-z]
        \u 	匹配[A-Z]
        \U 	匹配[^A-Z]
        \w 	匹配单词字母，等同于[0-9A-Za-z_]
        \W 	匹配单词字母之外的任意字符，等同于[^0-9A-Za-z_]
        \t 	匹配<TAB>字符
        \s 	匹配空白字符，等同于[\t]
        \S 	匹配非空白字符，等同于[^\t]

         

        一些普通字符需转意
        元字符	说明
        \* 	匹配* 字符
        \. 	匹配. 字符
        \/ 	匹配 / 字符
        \\	匹配 \ 字符
        \[ 	匹配 [ 字符
        \] 	匹配 ] 字符

         

        表示数量的元字符
        元字符	说明
        * 	匹配0-任意个
        \+ 	匹配1-任意个
        \? 	匹配0-1个
        \{n,m} 	匹配n-m个
        \{n} 	匹配n个
        \{n,} 	匹配n-任意个
        \{,m} 	匹配0-m个

         

        表示位置的元字符
        元字符	说明
        $ 	匹配行尾
        ^ 	匹配行首
        \< 	匹配单词词首
        \> 	匹配单词词尾

         

    替换变量

    在正则式中以\(和\)括起来的正则表达式，在后面使用的时候可以用\1、\2等变量来访问\(和\)中的内容。
例子

    删除行尾空格：:%s/\s\+$//g
    删除行首多余空格：%s/^\s*//g 或者 %s/^ *//
    删除沒有內容的空行 :g/^$/d
    删除包含有空格组成的空行：%s/^\s*$// 或者 g/^\s*$/d
    删除以空格或TAB开头到结尾的空行：%s/^[ |\t]*$// 或者 g/^[ |\t]*$/d

    把文中的所有字符串“abc……xyz”替换为“xyz……abc”可以有下列写法

    :%s/abc\(.*\)xyz/xyz\1abc/g
    :%s/\(abc\)\(.*\)\(xyz\)/\3\2\1/g

sed：指定文件进行替换

sed -i "s/from/to/g" 文件名


parted分区：
mklabel gpt
mkpart primary ext4 0% 100%
mkpart ext4 1 -1
mkpart ext4 2048s 100%




shell：
    # 取得数组元素的个数
    length=${#array_name[@]}
    # 或者
    length=${#array_name[*]}
    # 取得数组单个元素的长度
    lengthn=${#array_name[n]}


@和*表示数组元素

[oracle@rhel6 zxx_shell]$ cat 1-array.sh

#!/bin/bash

clxx=([8]=wiscom0 [3]=0256656 [0]=wiscom8)

echo "clxx[@]=${clxx[@]}"

echo "----------------"

echo "clxx[*]=${clxx[*]}"

[oracle@rhel6 zxx_shell]$ ./1-array.sh 

clxx[@]=wiscom8 0256656 wiscom0

----------------

clxx[*]=wiscom8 0256656 wiscom0

@和*表示数组元素表示数组所有元素。

[oracle@rhel6 zxx_shell]$ cat 1-array.sh

#!/bin/bash

clxx=([8]=wiscom0 [3]=0256656 [0]=wiscom8)

for i in ${clxx[@]}

do

    echo $i

done  

[oracle@rhel6 zxx_shell]$ ./1-array.sh 

wiscom8

0256656

wiscom0

打印时只输出赋值的元素。


@和*加引号打印区别

注意：当使用引号时，@和*打印有区别，@是逐个打印每个元素，*是把数组作为一个整体打印

[oracle@rhel6 zxx_shell]$ cat 1-array.sh

#!/bin/bash

clxx=([8]=wiscom0 [3]=0256656 [0]=wiscom8)

for i in "${clxx[@]}"

do

    echo $i

done  

[oracle@rhel6 zxx_shell]$ ./1-array.sh 

wiscom8

0256656

wiscom0

[oracle@rhel6 zxx_shell]$ vi 1-array.sh 

[oracle@rhel6 zxx_shell]$ cat 1-array.sh 

#!/bin/bash

clxx=([8]=wiscom0 [3]=0256656 [0]=wiscom8)

for i in "${clxx[*]}"

do

    echo $i

done  

[oracle@rhel6 zxx_shell]$ ./1-array.sh 

wiscom8 0256656 wiscom0






iozone:
bw:
iozone -r 1m -s 5g -i 0 -i 1 -I -c -e

iops:
iozone -r 4k -s 5g -i 0 -i 2  -O -I -c -e




wget下载指定目录下文件
wget -r -np -k -P ~/tmp/ http://xxx.com/download/
-P 表示下载到哪个目录
-r 表示递归下载
-np 表示不下载旁站连接.
-k 表示将下载的网页里的链接修改为本地链接.
-p 获得所有显示网页所需的元素
-c 断点续传
-nd 递归下载时不创建一层一层的目录，把所有的文件下载到当前目录

wget/curl获取响应信息
wget -d www.qq.com
wget -S www.qq.com   

curl -I www.qq.com




nfs安装配置：
yum -y install nfs-utils rpcbind

nfs 的配置文件 /etc/expots

vi /etc/exports
/opt/test/ 192.168.1.0/24(rw,root_squash,sync,anonuid=501,anongid=501)
注：配置文件说明：

/opt/test 为共享目录

192.168.1.0/24  可以为一个网段，一个IP，也可以是域名，域名支持通配符 如: *.qq.com

rw：read-write，可读写；

ro：read-only，只读；

sync：文件同时写入硬盘和内存；

async：文件暂存于内存，而不是直接写入硬盘

no_root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，也拥有root权限。显然开启这项是不安全的。

root_squash：NFS客户端连接服务端时如果使用的是root的话，那么对服务端分享的目录来说，拥有匿名用户权限，通常他将使用nobody或nfsnobody身份；

all_squash：不论NFS客户端连接服务端时使用什么用户，对服务端分享的目录来说都是拥有匿名用户权限；

anonuid：匿名用户的UID值，可以在此处自行设定。

anongid：匿名用户的GID值。

三、启动 nfs

service rpcbind start

service nfs start

systemctl enable rpcbind
systemctl enable nfs-server

查看状态
rpcinfo -p

四、客户端挂载：

yum    install   nfs-utils    -y

showmount -e 192.168.1.97            #查看可挂载

Export list for 192.168.1.97:

/opt/test          192.168.1.0/24

客户端挂载

mount -t nfs 192.168.1.97:/opt/test /mnt

无提示 既为成功

客户端在挂载的时候遇到的一个问题如下，可能是网络不太稳定，NFS默认是用UDP协议，换成TCP协议即可：

mount -t nfs 192.168.1.97:/opt/test /mnt -o proto=tcp -o nolock

开机自动挂载：
echo "192.168.1.97:/opt/test /mnt nfs defaults,_rnetdev 0 0" >> /etc/fstab

_rnetdev  表示无法挂载时直接跳过，避免无法挂载主机无法启动


vconfig add eth0 22
ifconfig eth0.22 192.168.22.176/24 up





需启用ip转发

 vi /etc/sysctl.conf

net.ipv4.ip_forward = 1

如果主机未启用防火墙，下面一条iptables语句就可设置nat内网共享上网：

Code:

iptables -t nat -A POSTROUTING -s 192.168.122.0/24 -o eth0 -j MASQUERADE

iptables -t nat -A POSTROUTING -o enp1s0 -j MASQUERADE
-s 表示源网络，即内网地址；-o 为连接因特网的接口



如果主机上启用了防火墙，需加上下面两句：

Code:

iptables -A FORWARD -s 192.168.122.0/24 -o eth0 -j ACCEPT
iptables -A FORWARD -d 192.168.122.0/24 -m state --state ESTABLISHED,RELATED -i eth0 -j ACCEPT

分别表示：来自内网、出口为eth0的包接受转发；来自eth0、目标地址为内网，且连接状态为建立、相关的包接受转发.

使用:

Code:

service iptables restart

重启iptables服务,将内网计算机网关设置为CentOS的Ip地址即可





iptables -F
iptables -t nat -F
iptables -P INPUT ACCEPT
iptables -P FORWARD ACCEPT
iptables -t nat -A POSTROUTING -s 192.168.0.170 -o enp1s0 -j MASQUERADE



iptables -t nat -A POSTROUTING -s 192.168.1.170 -o eth0 -j MASQUERADE


nc -vuz 183.62.15.114 4500    -v可视化，-u udp,-z扫描时不发送数据

nc传送文件：
接收机器上：nc -l 9999 >test.rar
发送机器上：nc 192.168.1.170 9999 <test.rar


nc传送文件夹：
接收机器上：nc -l 9999 |tar xvf -
发送机器上：tar cvf - * | nc 192.168.1.170 9999







 iscsiadm用法简介

已知192.168.14.112节点，存在目标器 iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzg，未设置CHAP，存在目标器 iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzgchap，设置CHAP用户名为mychap，CHAP密码为mypassword。

1、发现：

iscsiadm -m discovery -t st -p 192.168.14.112

2、登陆：
iscsiadm -m node -T iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzg -l（登陆某个目标器）

iscsiadm -m node -L all（登陆发现的所有目标器）

登入需验证码的节点，在登陆前需执行：

（1）开启认证
iscsiadm -m node -T  iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzgchap -o update --name node.session.auth.authmethod --value=CHAP
（2）添加用户
iscsiadm -m node -T  iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzgchap --op update --name node.session.auth.username --value=mychap
（3）添加密码
iscsiadm –m node –T  iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzgchap -–op update –name node.session.auth.password –value=mypassword

3、格式化：

mkfs.ext4 /dev/sdb (fdisk -l 查看设备)

4、退出
iscsiadm -m node -T iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzg -u（退出某个目标器）
iscsiadm -m node -U all（退出所有登陆的目标器）

连接死掉（断网或者target端断掉）时，使用如下指令：

iscsiadm -m node -o delete –T  iqn.2015.06.cn.hrbyg.www.ygcs.c0a802b8:wzgchap -p 192.168.14.112

5、查看session

iscsiadm -m session （相当于iscsiadm -m session -P 0）

iscsiadm -m session -P 3  (0-3均可，默认为0)

6、设置开机自动登录

sudo iscsiadm -m node -o update -n node.startup -v automatic （可与-T选项结合使用，manual为手动的）





KVM与XEN虚拟化环境究竟有何不同:
虚拟化的概念在近些年收到了很大程度上的普及，求其原因很简单：虚拟化能够最大程度利用资源，为企业节约成本。目前市面较受欢迎的虚拟架构主要有KVM、XEN和VMware，其中，KVM和XEN都是免费开源的，而VMware则是付费的.

如果给KVM、XEN简单归类的话，KVM是完全虚拟化技术又叫硬件辅助虚拟化技术（Full Virtualization)。相反，XEN是半虚拟化技术（paravirtualization），也叫做准虚拟化技术。

虚拟化技术通过在现有平台(机器)上添加一层薄的虚拟机监控程序(Virtual Machine Monitor，简称 VMM)软件而实现对系统的虚拟化，如虚拟处理器，虚拟内存管理器(MMU)和虚拟 I/O 系统等。虚拟机监控程序又被称之为监管程序(Hypervisor)。从应用程序的角度看，程序运行在虚拟机上同运行在其对应的实体计算机上一样。虚拟机技术使得一台物理计算机可以生成多个不同的虚拟机分别运行多个不同或相同的操作系统。虚拟机技术通过将不同的应用运行在不同的虚拟机上，可以避免不同应用程序之间的互相干扰，例如一个应用的崩溃不会影响到其它的应用等。这种由虚拟机技术实现的各个应用之间的完全隔离在服务器领域具有尤其重要的意义，同时虚拟机技术也可以使得企业、高校或研究所可以在不必购置大量物理计算机的情况下实现大规模的计算机网络以从事生产及研究，例如网络及网络应用研究，操作系统内核(Kernel)软件的开发和用户操作系统的开发等。

根据是否需要修改客户机操作系统，虚拟化技术又可以分为(1)泛虚拟化(Paravirtualization)和(2)完全虚拟化(Full-virtualization)。完全虚拟化由于不需要修改客户机操作系统，因此具有很好的兼容性和同时支持异种操作系统或不同版本操作系统的能力。相反泛虚拟化技术则通常具有比完全虚拟化技术更好的性能。

KVM最大的好处就在于它是与Linux内核集成的



mkdir ~/docker-registry && cd $_



ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime

[root@localhost share]# ll /etc/localtime 
lrwxrwxrwx. 1 root root 35 1月  24 2017 /etc/localtime -> ../usr/share/zoneinfo/Asia/Shanghai

timedatectl set-timezone Asia/Shanghai

[root@localhost share]# date -R
Mon, 14 Aug 2017 17:27:35 +0800

date -d @1361542596
date -d @1361542596 +"%Y-%m-%d %H:%M:%S"  #时间戳转换为时间
date -d @1361542596 +"%x-%X"


转换指定日期为Unix时间戳：date -d '2017-12-08 08:30:00' +%s





在HTTP应用中，存在一个问题，SERVER由于某种原因关闭连接，如KEEPALIVE的超时，这样，作为主动关闭的SERVER一方就会进入 FIN_WAIT2状态，但TCP/IP协议栈有个问题，FIN_WAIT2状态是没有超时的（不象TIME_WAIT状态），所以如果CLIENT不关闭，这个FIN_WAIT_2状态将保持到系统重新启动，越来越多的FIN_WAIT_2状态会致使内核crash。 

解决办法：修改/etc/sysctl.conf 文件：

net.ipv4.tcp_syncookies = 1
表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭

net.ipv4.tcp_fin_timeout = 30
表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。

net.ipv4.tcp_max_syn_backlog = 8192
表示SYN队列的长度，默认为1024，加大队列长度为8192，可以容纳更多等待连接的网络连接数。

net.ipv4.tcp_max_tw_buckets = 5000
表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，改为 5000。
对于Apache、Nginx等服务器，上几行的参数可以很好地减少TIME_WAIT套接字数量，但是对于Squid，效果却不大。此项参数可以控制TIME_WAIT套接字的最大数量，避免Squid服务器被大量的TIME_WAIT套接字拖死。





txt文件乱码：
使用命令iconv对文件内容编码进行转换：iconv -f gbk -tutf8 pos.txt > pos.txt.utf8

比较本地文件与远程文件的差异：
ssh username@host "cat remote_file" |diff local_file -




----------------------------------------------------------------
nginx配置负载均衡：
#设定负载均衡的服务器列表
upstream mysvr {
    #weigth参数表示权值，权值越高被分配到的几率越大
    server 192.168.105.27:8100  weight=1 max_fails=3 fail_timeout=30;
    server 192.168.105.41:8100  weight=1 max_fails=3 fail_timeout=30;
}

server {
     listen 8110;
     location / {
     proxy_pass http://mysvr;
     }
    }

----------------------------------------------------------------



使用nginx+dnsmasq解决同IP不同端口Session冲突问题：
由于一台服务器上需要部署多个项目，而我们的WEB项目因为用到框架都是一样的，导致同时运行，session相互冲突，这个登录后，那个就得重新登录，造成了使用不方便，原因是IP相同认为是同一个域,接收了B的set-cookie指令,把对应的cookie内容覆盖了,其中包括jsessionid,造成A的session丢失。 如果IP不同,则不会发生这个问题。IP相同的两个session对应的cookie是一样的，而不幸的是sessionID就保存在cookie中，这样先访问A，再访问B的时候，B的sessionid会覆盖A的sessionid。

        解决方法：

方法1：在不同的IP上进行部署。

方法2：修改应用服务器的配置，例如tomcat 7：

 context.xml：

 　　<Context path=”” docBase=”ROOT” sessionCookieName="workSessionId">  </Context>

方法3：使用不同的域名，这里介绍使用nginx+dnsmasq实现方法。

nginx部署在192.168.128.128，dnsmasq部署在192.168.128.100，应用均在192.168.128.100

nginx配置：

vi  /etc/nginx/conf.d /default.conf

server {
    listen       80;
    server_name  jenkins.qa.local;

    access_log /var/log/jenkins.log;

    location / {
        proxy_set_header Host $http_host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Real-Ip $remote_addr;
        proxy_set_header X-NginX-Proxy true;
        proxy_pass http://192.168.128.100:8080;
        proxy_redirect off;
    }
}


server {
    listen       80;
    server_name  shop.qa.local;

    access_log /var/log/shop.log;

    location / {
        proxy_set_header Host $http_host;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Real-Ip $remote_addr;
        proxy_set_header X-NginX-Proxy true;
        proxy_pass http://192.168.128.100;
        proxy_redirect off;
    }
}

server {
    listen       80;
    listen       443 ssl;
    server_name  mail.qa.local;

    access_log /var/log/mail.log;

    location / {
        return      301 https://192.168.128.100/mail;
    }

    location /admin {
        return      301 https://192.168.128.100/iredadmin;
    }

    #root /home/www;
    #ssl on;
    #ssl_certificate /etc/nginx/certs/server.crt;
    #ssl_certificate_key /etc/nginx/certs/server.key;
}
－－－－－－－－－－－－－－－－－－－－－－－－－－－－－
server {

    listen 8080;
    server_name portal.com;
    access_log /var/log/nginx/portal.log main;
    location / {
        #resolver 127.0.0.1;
        proxy_pass http://192.168.1.170:8080;
        proxy_read_timeout 180s;
        break;
    }

}

server {

    listen 8081;
    server_name boss.com;
    access_log /var/log/nginx/boss.log main;
    location / {
        #resolver 127.0.0.1;
        proxy_pass http://192.168.1.170:8081;
        proxy_read_timeout 180s;
        break;
    }

}
---------------------------------------------------------------- 

dnsmasq配置：

vi /etc/dnsmasq.conf

address=/qa.local/192.168.128.128







--------------------------------------------------------------------
问题：nginx做转发时，带'_'的header内容丢失。
原本在测试环境测试通过的APP，今天准备切到线上环境做最后测试，结果发现了错误。查看日志发现是APP端发送的http请求中的header内容丢失了。那么代码没有改动，怎么平白无故会丢失头信息？ 
于是想到两个环境的不同之处在于线上是通过nginx做的代理转发，会不会是nginx搞的鬼？于是搜索“nginx request header 丢失”，果不其然是这个问题，nginx对下划线的头信息做了限制，找到问题所在就等于完成了一大半，办法总比困难多。遂决定记录之。 
- 方法一：不用下划线 
既然nginx对下划线不支持，那没关系，不用下划线就是了。比如原来”app_version”改成”app-version”就可以了。（难怪一般header的name都是’-‘来拼接的，比如”User-Agent”） 
- 方法二：从根本接触nginx的限制 
nginx默认request的header的那么中包含’_’时，会自动忽略掉。 
解决方法是：在nginx里的nginx.conf配置文件中的http部分中添加如下配置： 
underscores_in_headers on; （默认 underscores_in_headers 为off）
----------------------------------------------------------------------


-------------------------------------------------------------------------------
问题：nginx配置websocket支持
WebSocket协议为创建客户端和服务器端需要实时双向通讯的webapp提供了一个选择。其为HTML5的一部分，WebSocket相较于原来开发这类app的方法来说，其能使开发更加地简单。大部分现在的浏览器都支持WebSocket，比如Firefox，IE，Chrome，Safari，Opera，并且越来越多的服务器框架现在也同样支持WebSocket。

在实际的生产环境中，要求多个WebSocket服务器必须具有高性能和高可用，那么WebSocket协议就需要一个负载均衡层，NGINX从1.3开始支持WebSocket，其可以作为一个反向代理和为WebSocket程序做负载均衡。

WebSocket协议不同于HTTP协议，但是WebSocket握手是通过HTTP来完成的，使用HTTP的Upgrade设施来升级连接从HTTP到WebSocket。这个允许WebSocket程序能够更简单地融入现有的基础设施。比如，WebSocket程序可以使用80和443标准的HTTP端口，从而允许使用存在的防火墙策略。

map $http_upgrade $connection_upgrade {
    default upgrade;
    ''      close;
}


#设定负载均衡的服务器列表
upstream mysvr {
    hash $request_uri consistent;
    #weigth参数表示权值，权值越高被分配到的几率越大
    server 192.168.105.27:8100  weight=1 max_fails=3 fail_timeout=30;
    server 192.168.105.44:8100  weight=1 max_fails=3 fail_timeout=30;
}

server {
     listen 8100;
     server_name mysvr:8100;
     location / {
        proxy_pass http://mysvr;

        proxy_redirect off;

        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header Host $host:$server_port;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
     }
}
----------------------------------------------------------------------


nginx 一致性hash模块
该模块可以根据配置参数采取不同的方式将请求均匀映射到后端机器，比如：
consistent_hash $remote_addr：可以根据客户端ip映射
consistent_hash $request_uri： 根据客户端请求的uri映射
consistent_hash $args：根据客户端携带的参数进行映射


-------------------------------------------------------------------------
nginx上传文件大小限制：
location / {
		proxy_pass     http://tomcat;
		client_max_body_size    100m;
	}






----------------------------------------------------------------------------
负载均衡集群中的session解决方案:

前言

在我们给Web站点使用负载均衡之后，必须面临的一个重要问题就是Session的处理办法，无论是PHP、Python、Ruby还是Java，只要使用服务器保存Session，在做负载均衡时都需要考虑Session的问题。

 

问题在哪里？如何处理？

会话保持（案例：Nginx、Haproxy）

会话复制（案例：Tomcat）

会话共享（案例：Memcached、Redis）

 

 

问题在哪里？

从用户端来解释，就是当一个用户第一次访问被负载均衡代理到后端服务器A并登录后，服务器A上保留了用户的登录信息；当用户再次发送请求时，根据负载均衡策略可能被代理到后端不同的服务器，例如服务器B，由于这台服务器B没有用户的登录信息，所以导致用户需要重新登录。这对用户来说是不可忍受的。所以，在实施负载均衡的时候，我们必须考虑Session的问题。

在负载均衡中，针对Session的处理，我们一般有以下几种方法：

Session 保持

Session 复制

Session 共享

 
会话保持
 

Session保持（会话保持）是我们见到最多的名词之一，通过会话保持，负载均衡进行请求分发的时候保证每个客户端固定的访问到后端的同一台应用服务器。会话保持方案在所有的负载均衡都有对应的实现。而且这是在负载均衡这一层就可以解决Session问题。

Nginx 做负载均衡的Session保持

对于Nginx可以选用Session保持的方法实行负载均衡，nginx的upstream目前支持5种方式的分配方式，其中有两种比较通用的Session解决方法，ip_hash和url_hash。注意：后者不是官方模块，需要额外安装。

ip_hash

每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，达到了Session保持的方法。

例：

upstream bakend {
   ip_hash;
   server192.168.0.11:80;
   server192.168.0.12:80;
 }

 

Haproxy做负载均衡的Session保持

    Haproxy作为一个优秀的反向代理和负载均衡软件，也提供了多种Session保持的方法，下面列举了两种最常用的：

源地址 Hash

haroxy 将用户IP经过hash计算后指定到固定的真实服务器上（类似于nginx 的ip hash 指令）

配置指令:balancesource

 

使用cookie 进行识别 

也就是Haproxy在用户第一次访问的后在用户浏览器插入了一个Cookie，用户下一次访问的时候浏览器就会带上这个Cookie给Haproxy，Haproxy进行识别。

配置指令:cookie  SESSION_COOKIE  insert indirect nocache

配置例子如下：

cookie SERVERID insert indirect nocache

server web01 192.168.56.11:8080 check cookie web01

server web02 192.168.56.12:8080 check cookie web02

 

会话保持的缺点：

会话保持看似解决了Session同步的问题，但是却带来的一些其它方面的问题：

负载不均衡了：由于使用了Session保持，很显然就无法保证负载绝对的均衡。

没有彻底解决问题：如果后端有服务器宕机，那么这台服务器的Session丢失，被分配到这台服务请求的用户还是需要重新登录。

 
会话复制
 
 

既然，我们的目标是所有服务器上都要保持用户的Session，那么将每个应用服务器中的Session信息复制到其它服务器节点上是不是就可以呢？这就是Session的第二中处理办法：会话复制。

  会话复制在Tomcat上得到了支持，它是基于IP组播（multicast）来完成Session的复制，Tomcat的会话复制分为两种：

全局会话复制：利用Delta Manager复制会话中的变更信息到集群中的所有其他节点。

非全局复制：使用Backup Manager进行复制，它会把Session复制给一个指定的备份节点。

    不过，这里我不准备来解释会话复制的Tomcat配置，如果有需求可以参考Tomcat官方文档，主要是因为会话复制不适合大的集群。根据笔者在生产的实践案例，当时是在集群超过6个节点之后就会出现各种问题，不推荐生产使用。

 

会话共享
 
既然会话保持和会话复制都不完美，那么我们为什么不把Session放在一个统一的地方呢，这样集群中的所有节点都在一个地方进行Session的存取就可以解决问题。

    Session存放到哪里？

对于Session来说，肯定是频繁使用的，虽然你可以把它存放在数据库中，但是真正生产环境中我更推荐存放在性能更快的分布式KV数据中，例如：Memcached和Redis。

 

PHP设置Session共享

如果你使用的是PHP那么恭喜你，配置非常的简单。PHP通过两行配置就可以把Session存放在Memcached或者Redis中，当然你要提前配置好他们。修改php.ini：

session.save_handler = memcache

session.save_path = "tcp://192.168.56.11:11211"

使用Redis存储Session

session.save_handler = redis

session.save_path ="tcp://localhost:6379"

提醒：别忘了给PHP安装memcache或者redis插件。

 

Tomcat设置Session共享

我们可以使用MSM（Memcached Session Manager）来实现同样把Session存放到Memcache中，GIthub地址如下：https://github.com/magro/memcached-session-manager目前支持Tomcat 6.x7.x和8.x的版本。

如果你想使用Redis，刚好也有开源的可以用，但是遗憾的是暂时不支持Tomcat 8.x的版本：https://github.com/jcoleman/tomcat-redis-session-manager

 

Django设置Session共享

在Django中Session是通过一个中间件管理的。如果要在应用程序中使用Session，需要在settings.py中的MIDDLEWARE_CLASSES变量中加入’django.contrib.sessions.middleware.SessionMiddleware’ 。Django的Session引擎可以将Session存放在三个地方，分别是：数据库、缓存、文件。

使用数据库保存Session

如果你想使用数据库支持的会话，你需要添加'django.contrib.sessions'到你的INSTALLED_APPS设置中。在配置完成之后，请运行manage.py migrate来安装保存会话数据的一张数据库表。

使用缓存保持Session

对于简单的缓存会话：

可以设置SESSION_ENGINE 为"django.contrib.sessions.backends.cache"。此时会话数据将直接存储在你的缓存中。然而，缓存数据将可能不会持久：如果缓存填满或者缓存服务器重启，缓存数据可能会被清理掉。

  若要持久的缓存数据：

可以设置SESSION_ENGINE为"django.contrib.sessions.backends.cached_db"。它的写操作使用缓存，对缓存的每次写入都将再写入到数据库。对于读取的会话，如果数据不在缓存中，则从数据库读取。两种会话的存储都非常快，但是简单的缓存更快，因为它放弃了持久性。大部分情况下，cached_db后端已经足够快，但是如果你需要榨干最后一点的性能，并且接受会话数据丢失的风险，那么你可使用cache而不是cached_db

使用文件保存Session

使用文件保存Session不再我们的讨论之类，因为很难进行共享，PHP默认也是将Session存放在/tmp目录下。

-------------------------------------------------------------------------------------------------------



----------------------------------------------------------------------
ubuntu配置远程连接：
1、XDMCP远程连接

vi /usr/share/lightdm/lightdm.conf.d/50-ubuntu-mate.conf

添加

greeter-show-manual-login=true

[XDMCPServer]
enabled=true

service lightdm restart

然后linux客户端就可以通过 X :5 -query  IP访问了。

 

2、远程桌面连接

xrdp与unity或者gnome不兼容，所以先安装mate桌面

apt-get install  ubuntu-mate-core  ubuntu-mate-desktop xrdp

然后vi /etc/xrdp/startwm.sh:
在. /etc/X11/Xsession前添加mate-session

最后echo mate-session> ~/.xsession

service xrdp restart

然后客户端就可以通过rdesktop远程连接了。


-------------------------------------------------------------------
apache允许列目录

vi /etc/httpd/conf.d/welcom.conf

<LocationMatch "^/+$">
    #Options -Indexes  #注释掉这一行

 

vi /etc/httpd/conf/httpd.conf

<Directory "/var/www/html">
    Options Indexes FollowSymLinks    #添加这一行
    Require all granted
</Directory>

service httpd restart

---------------------------------------------------------------------



cookie与session的区别：

1、cookie数据存放在客户的浏览器上，session数据放在服务器上。

2、cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗

考虑到安全应当使用session。

3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能

考虑到减轻服务器性能方面，应当使用cookie。

4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。

5、所以个人建议：

将登陆信息等重要信息存放为session
其他信息如果需要保留，可以放在cookie中



接口测试是测试系统组件间接口的一种测试。接口测试主要用于检测外部系统与系统之间以及内部各个子系统之间的交互点。测试的重点是要检查数据的交换，传递和控制管理过程，以及系统间的相互逻辑依赖关系等。
　　现在很多系统前后端架构是分离的，从安全层面来说，只依赖前端进行限制已经完全不能满足系统的安全要求（绕过前端太容易了）， 需要后端同样进行控制，在这种情况下就需要从接口层面进行验证。
　　如今系统越来越复杂，传统的靠前端测试已经大大降低了效率，而且现在我们都推崇测试前移，希望测试能更早的介入测试，那接口测试就是一种及早介入的方式。例如传统测试，你是不是得等前后端都完成你才能进行测试，才能进行自动化代码编写。 而如果是接口测试，只需要前后端定义好接口，那这时自动化就可以介入编写接口自动化测试代码，手工测试只需要后端代码完成就可以介入测试后端逻辑而不用等待前端工作完成。



所谓的mock就是创建一个类的虚假的对象，在测试环境中，用来替换掉真实的对象，以达到两大目的：
    1.验证这个对象的某些方法的调用情况，调用了多少次，参数是什么等等
    2.指定这个对象的某些方法的行为，返回特定的值，或者是执行特定的动作
要使用Mock，一般需要用到mock框架，这篇文章我们使用 Mockito 这个框架，这个是Java界使用最广泛的一个mock框架。



一个单体应用处理请求的所有逻辑都运行在一个单独的进程中，这种情况下，你可以在笔记本上开发、测试、部署都很简单，还可以通过负载均衡进行横向扩展，最后交付给运维团队。单体应用非常成功，但是越来越多的人感觉不妥，尤其是在云中部署的时候，任何微小的变更都要整体重新构建和部署，扩展的时候也需要整体扩展，不能进行部分扩展。这时候微服务架构风格就出现了，它提出将应用程序构建为一套服务，每个服务都可以独立部署和扩展，运行在独立的进程中，服务之间通过RPC调用进行通信。微服务的应用致力于松耦合和高内聚。
微服务架构有很多优点。例如，服务的拆分将复杂问题简单化；每个服务由专门的团队开发，开发者可以自由选择实现技术，提供API服务；每个微服务都可独立部署，加快了部署速度；每个服务可独立扩展以满足需求。
微服务的目的是有效地拆分应用，实现敏捷开发和部署；微服务应用都是分布式系统，需要通过RPC进程间通信完成服务调用，这样大大增加了系统的复杂性，因此必须写代码处理由于网络或者服务不可用等导致的调用失败问题，虽然一般框架都支持相关配置，但是在这种情况下微服务显得相对复杂些。



系统测试要求开发人员或测试人员在开展下一个测试类型之前进行以下几个方面的测试：
　　1、需要确保软件作为一个整体运行。
　　2、需要检查产品是否遗漏了任何一个功能性或非功能性需求。
　　3、需要在类生产环境中进行产品测试。
　　4、需要使用类似生产环境下的数据来进行产品测试。
系统测试包括基于业务风险的场景下的测试，用户使用场景下的测试或高级别的产品行为的测试。与不同系统资源交互的使用案例也应该成为系统测试的一部分。

系统测试可以在满足以下条件时启动：
　　1、对于所有没有任何开放性缺陷的单元，单元测试已成功完成。
　　2、所有经过单元测试的组件都很好地集成在一起，集成测试已成功完成。
　　3、伪生产环境可用于测试系统产品。
　　4、系统测试人员知道系统的所有输入/输出，并准备好测试工件。


端到端的测试检查从头开始直到覆盖所有从属系统的系统末端的活动流
系统测试人员需要具备真实用户的思维模式，而端到端测试人员需要同时了解上游和下游系统。如上所述，这两种测试类型在产品开发测试周期中同等重要，可以用它们来挖掘不同类别的缺陷。


--------------------------------------------------------
在一般情况下，升级服务器端应用，需要将应用源码或程序包上传到服务器，然后停止掉老版本服务，再启动新版本。但是这种简单的发布方式存在两个问题，一方面，在新版本升级过程中，服务是暂时中断的，另一方面，如果新版本有BUG，升级失败，回滚起来也非常麻烦，容易造成更长时间的服务不可用。

为了解决这些问题，人们研究出了多种发布策略，下面我们一一介绍。

蓝绿部署
所谓蓝绿部署，是指同时运行两个版本的应用，如上图所示，蓝绿部署的时候，并不停止掉老版本，而是直接部署一套新版本，等新版本运行起来后，再将流量切换到新版本上。但是蓝绿部署要求在升级过程中，同时运行两套程序，对硬件的要求就是日常所需的二倍，比如日常运行时，需要10台服务器支撑业务，那么使用蓝绿部署，你就需要购置二十台服务器。 

灰度发布
灰度发布也叫金丝雀发布，起源是，矿井工人发现，金丝雀对瓦斯气体很敏感，矿工会在下井之前，先放一只金丝雀到井中，如果金丝雀不叫了，就代表瓦斯浓度高。
在灰度发布开始后，先启动一个新版本应用，但是并不直接将流量切过来，而是测试人员对新版本进行线上测试，启动的这个新版本应用，就是我们的金丝雀。如果没有问题，那么可以将少量的用户流量导入到新版本上，然后再对新版本做运行状态观察，收集各种运行时数据，如果此时对新旧版本做各种数据对比，就是所谓的A/B测试。


当确认新版本运行良好后，再逐步将更多的流量导入到新版本上，在此期间，还可以不断地调整新旧两个版本的运行的服务器副本数量，以使得新版本能够承受越来越大的流量压力。直到将100%的流量都切换到新版本上，最后关闭剩下的老版本服务，完成灰度发布。

如果在灰度发布过程中（灰度期）发现了新版本有问题，就应该立即将流量切回老版本上，这样，就会将负面影响控制在最小范围内。


#!/bin/bash
rsync -avzP  --progress --exclude-from=/web/exclude.list  /${WORKSPACE}/*  172.16.0.36:/opt/php/saas-mall

echo "flush_all" |nc 127.0.0.1 11211



######nginx+php-fpm 上传大文件报502 Bad Gateway#######

nginx的配置/etc/nginx/nginx.conf:
user apps apps;

worker_processes 4;
worker_cpu_affinity 0001 0010 0100 1000;

error_log /opt/logs/nginx/error.log crit;
daemon on;

pid /run/nginx.pid;

#Specifies the value for maximum file descriptors that can be opened by this process.
worker_rlimit_nofile 65535;

events
{
        use epoll;
        worker_connections 65535;
}

http
{
        include         mime.types;
        default_type    application/octet-stream;
        access_log  /opt/logs/nginx/access.log;

        #charset        gb2312;

        server_names_hash_bucket_size 128;
        client_header_buffer_size 4k;
        large_client_header_buffers 4 32k;
        client_max_body_size 80m;

        sendfile on;
        tcp_nopush on;

        client_body_timeout     300;
        client_header_timeout   300;
        keepalive_timeout       300;
        send_timeout            300;


        open_file_cache max=65535 inactive=20s;
        open_file_cache_valid 30s;
        open_file_cache_min_uses 1;

        tcp_nodelay on;

        fastcgi_connect_timeout 300;
        fastcgi_send_timeout    300;
        fastcgi_read_timeout    300;
        fastcgi_buffer_size     256k;
        fastcgi_buffers         16 256k;
        fastcgi_busy_buffers_size 512k;
        fastcgi_temp_file_write_size 512k;
        fastcgi_intercept_errors on;

        client_body_buffer_size 512k;
        proxy_request_buffering off;
        proxy_buffering off;
        
        proxy_connect_timeout   300;
        proxy_read_timeout      300;
        proxy_send_timeout      300;
        #proxy_buffer_size       16k;
        #proxy_buffers           4 64k;
        #proxy_busy_buffers_size 128k;
        proxy_temp_file_write_size 128k;

        gzip on;
        gzip_min_length 1k;
        gzip_buffers    4 16k;
        gzip_http_version 1.0;
        gzip_comp_level 2;
        gzip_types      text/plain application/x-javascript text/css application/xml application/json;
        gzip_vary on;

        #limit_zone     crawler $binary_remote_addr     10m;
        proxy_temp_path /dev/shm/temp;
        proxy_cache_path /dev/shm/cache levels=2:2:2 keys_zone=cache_go:100m inactive=5d max_size=5g;

        log_format log_access
                "$remote_addr"
                "\t$remote_user"
                "\t$time_local"
                "\t$request"
                "\t$request_time"
                "\t$upstream_response_time"
                "\t$status"
                "\t$body_bytes_sent"
                "\t$http_referer"
                "\t$http_user_agent"
                "\t$http_x_forwarded_for"
                "\t$host"
                "\t$hostname"
                #"\t$request_body"
                "\t-";

        include /etc/nginx/conf.d/*.conf;
}



php的修改
/etc/php.ini:
max_execution_time 300
max_input_time 300
upload_max_filesize 500M
post_max_size 500M


/etc/php-fpm.d/www.conf:
request_terminate_timeout = 0




跨域：
1、什么是跨域

简单地理解就是因为JavaScript同源策略的限制，a.com 域名下的js无法操作b.com或是c.a.com域名下的对象。

同源是指相同的协议、域名、端口。特别注意两点：

如果是协议和端口造成的跨域问题“前台”是无能为力的，

在跨域问题上，域仅仅是通过“协议+域名+端口”来识别，两个不同的域名即便指向同一个ip地址，也是跨域的。

http://www.a.com:8000/a.js
http://www.a.com/b.js              同一域名，不同端口                不允许


http://www.a.com/a.js
https://www.a.com/b.js             同一域名，不同协议                不允许

http://www.a.com/a.js
http://script.a.com/b.js        主域相同，子域不同            不允许


http://www.a.com/a.js
http://a.com/b.js           同一域名，不同二级域名    不允许（cookie这种情况下也不允许访问）



2、nginx配置跨域
location /api {
	proxy_pass   http://88.128.19.209:8081/api;
	add_header Access-Control-Allow-Methods *;
	add_header Access-Control-Max-Age 3600;
	add_header Access-Control-Allow-Credentials true;
	add_header Access-Control-Allow-Origin $http_origin;
	add_header Access-Control-Allow-Headers $http_access_control_request_headers;

	if ($request_method = OPTIONS ) {
		return 200;
	}
}

跨域等许多nginx配置可能比较常用，可以把其放入单独文件中，然后include，这样其他api都可以include这个公共配置

common/set_proxy_header文件：
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
proxy_set_header REMOTE-HOST $remote_addr;
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
		
common/set_cross_header文件：
add_header Access-Control-Allow-Methods *;
add_header Access-Control-Max-Age 3600;
add_header Access-Control-Allow-Credentials true;
add_header Access-Control-Allow-Origin $http_origin;
add_header Access-Control-Allow-Headers $http_access_control_request_headers;

if ($request_method = OPTIONS ) {
    return 200;
}

nginx.conf:
location /api {
	proxy_pass   http://88.128.19.209:8081/api;
	include common/set_proxy_header;
	include common/set_cross_header;
}









# location ~* ^/public/getTopicStyle/(\d+)$ {
#         proxy_redirect off;
#         proxy_pass_header HEADER-NOME-CorpID;
#         proxy_pass_header HEADER-NOME-AppID;
#         proxy_pass_header HEADER-NOME-UID;
#         proxy_pass http://basecenter;
# }


location / {
		set $cors '';
		if ($http_origin ~* 'https?://(localhost|sales\.bk\.nome\.cn)') {
				set $cors 'true';
		}

		if ($cors = 'true') {
				add_header 'Access-Control-Allow-Origin' "$http_origin";
				add_header 'Access-Control-Allow-Credentials' 'true';
				add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS';
				add_header 'Access-Control-Allow-Headers' 'Accept,Authorization,Cache-Control,Content-Type,DNT,If-Modified-Since,Keep-Alive,Origin,User-Agent,X-Mx-ReqToken,X-Requested-With';
		}

		if ($request_method = 'OPTIONS') {
				return 204;
		}
		proxy_pass http://aurora-dev;
}





====================================================================
springboot启动时会创建一个/tmp/tomcat.*/work/Tomcat/localhost/ROOT的临时目录作为文件上传的临时目录，但是该目录会在n天之后被系统自动清理掉，这个清理是由linux操作系统完成的，具体的配置如下:

vim /usr/lib/tmpfiles.d/tmp.conf
vim /etc/tmpfiles.d/tmp.conf

# 添加一行
x /tmp/tomcat.*
====================================================================



====================================================================
解决macos ssh连接不上linux服务器问题
vi /etc/ssh/ssh_config:

Host *
	SendEnv LANG LC_*
        # macOS Mojave 需要设置为 no 否则照样会断开
		
        TCPKeepAlive no

        # 客户端每隔 60S 发送一个空报文
        ServerAliveInterval 60

        # macOS Mojave 需要增加，原因在于Qos检测命令不被对端支持，导致连接丢失
        # packet_write_wait: Connection to 10.10.10.111 port 22: Broken pipe
        IPQoS lowdelay throughput
		
		
====================================================================
缓存和数据库数据一致性问题：分布式环境下非常容易出现缓存和数据库间数据一致性问题，针对这一点，如果项目对缓存的要求是强一致性的，那么就不要使用缓存。

我们只能采取合适的策略来降低缓存和数据库间数据不一致的概率，而无法保证两者间的强一致性。


合适的策略包括合适的缓存更新策略，更新数据库后及时更新缓存、缓存失败时增加重试机制。

缓存穿透：
缓存穿透的概念很简单，用户想要查询一个数据，发现redis内存数据库没有，也就是缓存没有命中，于是向持久层数据库查询。发现也没有，于是本次查询失败。当用户很多的时候，缓存都没有命中，于是都去请求了持久层数据库。这会给持久层数据库造成很大的压力，这时候就相当于出现了缓存穿透。

这里需要注意和缓存击穿的区别，缓存击穿，是指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。

缓存穿透是指查询一个数据库一定不存在的数据。正常的使用缓存流程大致是，数据查询先进行缓存查询，如果key不存在或者key已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存。想象一下这个情况，如果传入的参数是一个不存在的对象。就会每次都去查询数据库，而每次查询都是空，每次又都不会进行缓存。假如有恶意攻击，就可以利用这个漏洞，对数据库造成压力，甚至压垮数据库。

处理办法：会采用缓存空值的方式，如果从数据库查询的对象为空，也放入缓存，只是设定的缓存过期时间较短，比如设置为60秒。缓存空值不能设置太久，否则NULL数据长时间得不到更新，也不能太短，否则达不到防止缓存击穿的效果。当NULL缓存过期我还可以使用限流，缓存预热等手段来防止穿透。应对缓存穿透的常用方法之一是限流，常见的限流算法有滑动窗口，令牌桶算法和漏桶算法，或者直接使用队列、加锁等。

如果空值能够被缓存起来，这就意味着缓存需要更多的空间存储更多的键，因为这当中可能会有很多的空值的键；
即使对空值设置了过期时间，还是会存在缓存层和存储层的数据会有一段时间窗口的不一致，这对于需要保持一致性的业务会有影响。


缓存击穿：在高并发下，对一个特定的值进行查询，但是这个时候缓存正好过期了，缓存没有命中，导致大量请求直接落到数据库上，如活动系统里面查询活动信息，但是在活动进行过程中活动缓存突然过期了。
其实，大多数情况下这种爆款很难对数据库服务器造成压垮性的压力。达到这个级别的公司没有几家的。所以，务实主义的小编，对主打商品都是早早的做好了准备，让缓存永不过期。即便某些商品自己发酵成了爆款，也是直接设为永不过期就好了。
解决方案：
1、设置热点数据永远不过期。
2、加互斥锁
3、双缓存
4、检查更新

设置一级缓存和二级缓存，一级缓存过期时间短，二级缓存过期时间长或者不过期，一级缓存失效后访问二级缓存，同时刷新一级缓存和二级缓存。

双缓存的方式，说白了就是不能将一级缓存和二级缓存中数据同时变成失效，当一级缓存失效后，有多个请求访问，彼此之间依然是竞争锁，抢到锁的线程查询数据库并刷新缓存，而其他没有抢到锁的线程，直接访问二级缓存。

检查更新：
每次get缓存的时候，都把数据的过期时间和当前时间进行一下对比，当间隔时间小于一个阈值的时候，主动更新缓存。

比如（缓存过期时间 - 当前系统时间）小于 5 分钟，那么就刷新一次缓存，并且重置缓存过期时间；

不过这个方法也有个致命的问题：如果一个数据，恰好在缓存失效前五分钟，一次访问都没有，那么就不会触发检查更新，当缓存失效后有大量请求访问，那么也会造成缓存击穿。





缓存雪崩：同一时间大面积失效，瞬间 Redis 跟没有一样，那这个数量级别的请求直接打到数据库几乎是灾难性的。或者是redis挂了不能正常工作了。于是所有的请求都会打到存储层，存储层的调用量会暴增，造成存储层也会挂掉的情况。也可是指在某一个时间段，缓存集中过期失效。产生雪崩的原因之一，比如在写本文的时候，马上就要到双十二零点，很快就会迎来一波抢购，这波商品时间比较集中的放入了缓存，假设缓存一个小时。那么到了凌晨一点钟的时候，这批商品的缓存就都过期了。而对这批商品的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。小编在做电商项目的时候，一般是采取不同分类商品，缓存不同周期。在同一分类中的商品，加上一个随机因子。这样能尽可能分散缓存过期时间，而且，热门类目的商品缓存时间长一些，冷门类目的商品缓存时间短一些，也能节省缓存服务的资源。其实集中过期，倒不是非常致命，比较致命的缓存雪崩，是缓存服务器某个节点宕机或断网。因为自然形成的缓存雪崩，一定是在某个时间段集中创建缓存，那么那个时候数据库能顶住压力，这个时候，数据库也是可以顶住压力的。无非就是对数据库产生周期性的压力而已。而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。

解决方案：
（1）redis高可用

这个思想的含义是，既然redis有可能挂掉，那我多增设几台redis，这样一台挂掉之后其他的还可以继续工作，其实就是搭建的集群。

（2）批量往 Redis 存数据的时候，把每个 Key 的失效时间都加个随机值就好了，这样可以保证数据不会再同一时间大面积失效。

setRedis（key, value, time+Math.random()*10000）;



（3）限流降级

这个解决方案的思想是，在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。

（4）数据预热

数据加热的含义就是在正式部署之前，我先把可能的数据先预先访问一遍，这样部分可能大量访问的数据就会加载到缓存中。在即将发生大并发访问前手动触发加载缓存不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。

（5）设置热点数据永不过期


=============================================

Redis 的持久化策略有两种：

RDB：快照形式是直接把内存中的数据保存到一个 dump 的文件中，定时保存，保存策略。AOF：把所有的对 Redis 的服务器进行修改的命令都存到一个文件里，命令的集合。Redis 默认是快照 RDB 的持久化方式。

当 Redis 重启的时候，它会优先使用 AOF 文件来还原数据集，因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。你甚至可以关闭持久化功能，让数据只在服务器运行时存。

面试官：那你再说下 RDB 是怎么工作的？

我：默认 Redis 是会以快照"RDB"的形式将数据持久化到磁盘的一个二进制文件 dump.rdb。

工作原理简单说一下：当 Redis 需要做持久化时，Redis 会 fork 一个子进程，子进程将数据写到磁盘上一个临时 RDB 文件中。

当子进程完成写临时文件后，将原来的 RDB 替换掉，这样的好处是可以 copy-on-write。

我：RDB 的优点是：这种文件非常适合用于备份：比如，你可以在最近的 24 小时内，每小时备份一次，并且在每个月的每一天也备份一个 RDB 文件。

这样的话，即使遇上问题，也可以随时将数据集还原到不同的版本。RDB 非常适合灾难恢复。

RDB 的缺点是：如果你需要尽量避免在服务器故障时丢失数据，那么RDB不合适你。

面试官：那你要不再说下 AOF？

我：（说就一起说下吧）使用 AOF 做持久化，每一个写命令都通过 write 函数追加到 appendonly.aof 中，配置方式如下：

appendfsyncyesappendfsync always #每次有数据修改发生时都会写入AOF文件。appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。

AOF 可以做到全程持久化，只需要在配置中开启 appendonly yes。这样 Redis 每执行一个修改数据的命令，都会把它添加到 AOF 文件中，当 Redis 重启时，将会读取 AOF 文件进行重放，恢复到 Redis 关闭前的最后时刻。

我顿了一下，继续说：使用 AOF 的优点是会让 Redis 变得非常耐久。可以设置不同的 Fsync 策略，AOF的默认策略是每秒钟 Fsync 一次，在这种配置下，就算发生故障停机，也最多丢失一秒钟的数据。

缺点是对于相同的数据集来说，AOF 的文件体积通常要大于 RDB 文件的体积。根据所使用的 Fsync 策略，AOF 的速度可能会慢于 RDB。

面试官又问：你说了这么多，那我该用哪一个呢？

我：如果你非常关心你的数据，但仍然可以承受数分钟内的数据丢失，那么可以额只使用 RDB 持久。

AOF 将 Redis 执行的每一条命令追加到磁盘中，处理巨大的写入会降低Redis的性能，不知道你是否可以接受。

数据库备份和灾难恢复：定时生成 RDB 快照非常便于进行数据库备份，并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度快。

当然了，Redis 支持同时开启 RDB 和 AOF，系统重启后，Redis 会优先使用 AOF 来恢复数据，这样丢失的数据会最少。


save，bgsave，auto

自动触发是由我们的配置文件来完成的。
在redis.conf配置文件中，里面有如下配置，我们可以去设置触发Redis的RDB 持久化条件，也就是什么时候将内存中的数据保存到硬盘。

比如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。

默认如下配置：

#表示900 秒内如果至少有 1 个 key 的值变化，则保存
save 900 1

#表示300 秒内如果至少有 10 个 key 的值变化，则保存
save 300 10

#表示60 秒内如果至少有 10000 个 key 的值变化，则保存
save 60 10000

AOF也有三种触发机制

（1）每修改同步always：同步持久化 每次发生数据变更会被立即记录到磁盘 性能较差但数据完整性比较好

（2）每秒同步everysec：异步操作，每秒记录 如果一秒内宕机，有数据丢失

（3）no：从不同步

==============================================================================



jstat -gcutil pid 2s 10：可以查看内存增长速度和区域


k8s架构：
一个K8S系统，通常称为一个K8S集群（Cluster）。
这个集群主要包括两个部分：

    一个Master节点（主节点）一群Node节点（计算节点）
	
Master节点主要还是负责管理和控制。Node节点是工作负载节点。

Master节点包括API Server、Scheduler、Controller manager、etcd。
	API Server是整个系统的对外接口，供客户端和其它组件调用，相当于“营业厅”。
	Scheduler负责对集群内部的资源进行调度，相当于“调度室”。
	Controller manager负责管理控制器，相当于“大总管”。

apiserver读写数据到etcd，其他组件通过apiserver读写，然后执行操作



Node节点包括Docker、kubelet、kube-proxy、Fluentd、kube-dns（可选），还有就是Pod。
Pod是Kubernetes最基本的操作单元。一个Pod代表着集群中运行的一个进程，它内部封装了一个或多个紧密相关的容器。除了Pod之外，K8S还有一个Service的概念，一个Service可以看作一组提供相同服务的Pod的对外访问接口。




缺陷趋势分析图，不可能达到理想状态，可能原因如下：
1、缺陷处理流程有问题
2、修复缺陷，引入了新的缺陷
3、有的功能模块被漏测
4、修复缺陷的速度跟不上
5、回归策略有问题


根据具体的缺陷发现情况，可以绘制出如下4条曲线。

    （1）发现数，累计的所有被发现的缺陷数量。 

    （2）关闭数，累计的所有被关闭的缺陷数量。

    （3）日发现，当日（当期）发现的缺陷数量。

    （4）日关闭，当日（当期）关闭的缺陷数量。

其中，发现数和关闭数是两条关键的趋势曲线。
对于使用如此分析的缺陷趋势图，可以初步分析出如下几种情况。
	  
趋势分析：
1、缺陷发现和关闭的趋势基本一致，说明测试过程中的缺陷能被开发人员及时修复，软件处于开发前期或中期
2、测试期间每天发现的新缺陷数量较少，或几乎为0直到成为一条平滑直线，说明缺陷处于收敛状态
3、当发现数与关闭数的曲线相交于一点时，说明发现的缺陷都进行了修改而被关闭，软件处于可发布状态，但这样的情况下，有风险，因为这个时候针对于新的版本来说，只是最多进行了回归测试，可能还存在需要更多的新的用例的补充来进行测试。
4、正常看，提测准入通过的1-2天后每日新增应该在一个高峰值，总体呈下降趋势，最后趋向于0。整个测试周期，80%＋的bug发现在测试周期中前期，测试后期甚至回归测试的bug新增数趋于平稳到0，可以说明测试效率是比较高的，测试质量较高，且开发修复bug新引入bug的概率是比较小的
5、每日关闭(closed)趋势反映了开发对bug处理响应快，修复bug效率高，累计活跃的(all-active)bug得到收敛
6、如果新建的bug越来越少，但关闭的bug曲线一直在打开bug下面，说明，瓶颈在研发那边，他修改bug的效率过低



SQL问题：
	看看是索引问题，还是数据量问题，还是sql写法导致索引失效；
	
	

	
curl用法：
1. Content-Type
当使用POST方法提交数据时，对于提交的数据主要有如下四种形式：
1、application/x-www-form-urlencoded：默认的形式，即key1=value1&key2=value2的形式；
2、multipart/form-data：使用表单上传文件时使用这个形式；
3、application/json：提交JSON格式的数据；
4、text/xml：提交XML格式的数据。


Content-Type是一个Header，如果不指定的话，那么默认就是使用application/x-www-form-urlencoded形式传输数据，当需要使用别的形式进行数据传输的话，那么就需要指定这个Header


使用-d参数以后，HTTP 请求会自动加上标头Content-Type : application/x-www-form-urlencoded。并且会自动将请求转为 POST 方法，因此可以省略-X POST

$ curl -d 'login=emma＆password=123' -X POST https://google.com/login
# 或者
$ curl -d 'login=emma' -d 'password=123' -X POST  https://google.com/login

-d参数可以读取本地文本文件的数据，向服务器发送。
$ curl -d '@data.txt' https://google.com/login

--data-urlencode参数等同于-d，发送 POST 请求的数据体，区别在于会自动将发送的数据进行 URL 编码。
$ curl --data-urlencode 'comment=hello world' https://google.com/login
上面代码中，发送的数据hello world之间有一个空格，需要进行 URL 编码。


$ curl -F 'file=@photo.png;type=image/png' https://google.com/profile
上面命令指定 MIME 类型为image/png，否则 curl 会把 MIME 类型设为application/octet-stream。

$ curl -F 'file=@photo.png;filename=me.png' https://google.com/profile
上面命令中，原始文件名为photo.png，但是服务器接收到的文件名为me.png。


$ curl -d '{"login": "emma", "pass": "123"}' -H 'Content-Type: application/json' https://google.com/login


-I参数向服务器发出 HEAD 请求，然会将服务器返回的 HTTP 标头打印出来。
curl -I www.baidu.com






linux时间戳转换：

date -d @1584149938 +"%Y-%m-%d %H:%M:%S"
2020-03-14 09:38:58

date -d "2020-03-14 09:38:58" +%s
1584149938



=============================================
为毛不用memcached
1、存储方式上：
	MC把全部数据存在内存之中，数据不能超过内存大小。不支持数据持久化，断电后数据没了
2、数据类型上：		  mc只支持简单的key-value，redis支持五种数据类型：string（二进制安全，最大存储512M）、hash、list、set、zset
	

redis慢日志查询：
	slowlog get
	
	
redis优点：
	性能优秀，数据在内存中，读写速度非常快，采用单进程单线程，避免了不必要的上下文切换。支持5种数据类型，支持数据持久化，可以将内存中数据保存在磁盘中。
	

mongodb：
	文档型数据库
	